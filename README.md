## **Decision Tree Model from Scratch**  

This project is an implementation of a **Decision Tree** classifier from scratch using Python. Instead of relying on existing libraries like `scikit-learn`, I built the model step by step, handling **data splitting, information gain calculation, tree construction, and prediction** manually. Through this project, I gained a deeper understanding of how decision trees work internally, including concepts like **entropy, Gini impurity, recursion, and tree pruning**.  

### **Key Features**  
âœ”ï¸ Implementation of a **Decision Tree Classifier** from scratch  
âœ”ï¸ Supports **both categorical and numerical** data  
âœ”ï¸ Uses **Entropy & Gini Impurity** for decision-making  
âœ”ï¸ Implements **recursive tree building** and **leaf node assignment**  
âœ”ï¸ Provides **custom prediction** for new data  

---

## **How to Use the Model**  

### **1. Clone the Repository**  
```sh
git clone https://github.com/MohWasil/Decision_Tree_model_from_scratch.git
cd Decision_Tree_model_from_scratch
```

### **2. Install Dependencies**  
```sh
pip install -r requirements.txt
```

### **3. Run the Model**  
Execute the Python script to train and test the model:  
```sh
python decision_tree.py
```

### **4. Modify and Test with Your Own Data**  
- Replace the dataset inside `data.csv`  
- Adjust parameters in `decision_tree.py`  
- Run the script again to see the results  

---

## **What I Learned**  
ğŸ“Œ Understanding of **entropy, Gini impurity, and information gain**  
ğŸ“Œ How to **split datasets** efficiently based on features  
ğŸ“Œ Implementing **recursive tree structures**  
ğŸ“Œ The importance of **handling overfitting** with pruning  
ğŸ“Œ Writing clean, modular code for machine learning  

---

## **Contributing**  
Feel free to **fork** the repository, open **issues**, or submit **pull requests**. Your contributions are welcome!  

---
